{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhhyqasIWm_8"
      },
      "source": [
        "# Sistema de Recomendação por Imagens\n",
        "\n",
        "Este notebook implementa um sistema de recomendação de produtos baseado em similaridade visual, adaptado para execução no Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssvxn4WuWnAD"
      },
      "source": [
        "## 1. Configuração do Ambiente\n",
        "\n",
        "Primeiro, instalamos as dependências necessárias e garantimos que o TensorFlow não utilizará a GPU, forçando a execução em CPU para consistência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQfCGKRKWnAG",
        "outputId": "7c5cacab-56b5-4a43-f999-325dc78e52ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow Pillow scikit-learn keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vGzq0LIWnAK",
        "outputId": "d91e4119-7de5-4ef2-8866-5b7d716e2c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow rodando em: CPU\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Desabilita GPUs\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow rodando em:', 'CPU' if not tf.config.list_physical_devices('GPU') else 'GPU') # Confirma o dispositivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPyzG1JiWnAL"
      },
      "source": [
        "## 2. Download e Preparação dos Dados\n",
        "\n",
        "Baixamos o dataset Caltech 101 e o extraímos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz65asx4WnAL",
        "outputId": "4c5482cc-d3b6-4729-d6f5-568127f98f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-17 06:29:36--  https://data.caltech.edu/records/mzrjq-6wc02/files/101_ObjectCategories.tar.gz\n",
            "Resolving data.caltech.edu (data.caltech.edu)... 35.155.11.48\n",
            "Connecting to data.caltech.edu (data.caltech.edu)|35.155.11.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 500 INTERNAL SERVER ERROR\n",
            "2025-09-17 06:29:36 ERROR 500: INTERNAL SERVER ERROR.\n",
            "\n",
            "tar (child): 101_ObjectCategories.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.caltech.edu/records/mzrjq-6wc02/files/101_ObjectCategories.tar.gz\n",
        "!tar -xzf 101_ObjectCategories.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDFcJ1waWnAM"
      },
      "source": [
        "## 3. Definição das Classes e Funções\n",
        "\n",
        "Aqui definimos todas as classes e funções necessárias para o sistema, como `FeatureExtractor`, `Recommender` e a função de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XRTqXVpGWnAN"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, model_path):\n",
        "        base_model = load_model(model_path)\n",
        "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('feature_extraction_layer').output)\n",
        "\n",
        "    def _preprocess_image(self, img_path):\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        return x\n",
        "\n",
        "    def extract_feature(self, img_path):\n",
        "        x = self._preprocess_image(img_path)\n",
        "        feature = self.model.predict(x)[0]\n",
        "        return feature / np.linalg.norm(feature)\n",
        "\n",
        "    def extract_features_from_paths(self, path_list):\n",
        "        features = {}\n",
        "        for img_path in path_list:\n",
        "            try:\n",
        "                feature = self.extract_feature(img_path)\n",
        "                features[img_path] = feature\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar {img_path}: {e}\")\n",
        "        return features\n",
        "\n",
        "    def save_features(self, features, filepath=\"features.pkl\"):\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(features, f)\n",
        "\n",
        "    def load_features(self, filepath=\"features.pkl\"):\n",
        "        with open(filepath, 'rb') as f:\n",
        "            return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P77dWOakWnAO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class Recommender:\n",
        "    def __init__(self, features_dict):\n",
        "        self.features_dict = features_dict\n",
        "        self.image_paths = list(features_dict.keys())\n",
        "        self.feature_list = list(features_dict.values())\n",
        "\n",
        "    def get_recommendations(self, query_image_path, top_k=5):\n",
        "        if query_image_path not in self.features_dict:\n",
        "            raise ValueError(\"Imagem de consulta não encontrada no dicionário de features.\")\n",
        "\n",
        "        query_feature = self.features_dict[query_image_path]\n",
        "        similarities = cosine_similarity([query_feature], self.feature_list)[0]\n",
        "        scores = list(zip(self.image_paths, similarities))\n",
        "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        final_recommendations = []\n",
        "        for path, score in sorted_scores:\n",
        "            if path != query_image_path:\n",
        "                final_recommendations.append((path, score))\n",
        "            if len(final_recommendations) == top_k:\n",
        "                break\n",
        "\n",
        "        return final_recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i70fzZQvWnAQ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def train_model(data_dir, selected_classes, model_save_path, epochs=10, batch_size=32, img_height=224, img_width=224):\n",
        "    temp_data_dir = \"temp_data_for_training\"\n",
        "    if os.path.exists(temp_data_dir):\n",
        "        shutil.rmtree(temp_data_dir)\n",
        "\n",
        "    for class_name in selected_classes:\n",
        "        shutil.copytree(os.path.join(data_dir, class_name), os.path.join(temp_data_dir, class_name))\n",
        "\n",
        "    print(f\"Dados das classes {selected_classes} copiados para {temp_data_dir}\")\n",
        "\n",
        "    print(\"Carregando e dividindo o dataset...\")\n",
        "    train_ds = keras.utils.image_dataset_from_directory(\n",
        "        temp_data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    val_ds = keras.utils.image_dataset_from_directory(\n",
        "        temp_data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "    print(f\"Classes encontradas para o treinamento: {class_names}\")\n",
        "\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    print(\"Construindo o modelo com base no VGG16...\")\n",
        "    base_model = keras.applications.VGG16(\n",
        "        input_shape=(img_height, img_width, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "    x = keras.applications.vgg16.preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = keras.layers.GlobalAveragePooling2D(name=\"feature_extraction_layer\")(x)\n",
        "    x = keras.layers.Dense(128, activation='relu')(x)\n",
        "    outputs = keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    print(\"Compilando e iniciando o treinamento...\")\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    print(f\"Salvando o modelo treinado em: {model_save_path}\")\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    shutil.rmtree(temp_data_dir)\n",
        "    print(f\"Diretório temporário {temp_data_dir} removido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlqsVNklWnAS"
      },
      "source": [
        "## 4. Execução Principal\n",
        "\n",
        "Agora, executamos a lógica principal: treinar o modelo (se necessário), extrair features e obter recomendações para uma imagem aleatória."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_W6JMmO3WnAU",
        "outputId": "a56938fc-e838-4a93-cdc8-e7fdf8aebffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo fine_tuned_model.keras não encontrado. Iniciando o treinamento...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '101_ObjectCategories/laptop'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4027366141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modelo {MODEL_PATH} não encontrado. Iniciando o treinamento...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSELECTED_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modelo {MODEL_PATH} encontrado.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3397977842.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_dir, selected_classes, model_save_path, epochs, batch_size, img_height, img_width)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dados das classes {selected_classes} copiados para {temp_data_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[1;32m    597\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shutil.copytree\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '101_ObjectCategories/laptop'"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import glob\n",
        "\n",
        "SELECTED_CLASSES = ['laptop', 'watch', 'cellphone', 'cup']\n",
        "MODEL_PATH = \"fine_tuned_model.keras\"\n",
        "FEATURES_PATH = \"features_fine_tuned.pkl\"\n",
        "DATA_DIR = \"101_ObjectCategories\"\n",
        "\n",
        "def get_random_image(root_dir, class_list):\n",
        "    random_class = random.choice(class_list)\n",
        "    class_dir = os.path.join(root_dir, random_class)\n",
        "    all_images = glob.glob(os.path.join(class_dir, 'image_*.jpg')) # Ajustado para o dataset que usa .jpg\n",
        "    return random.choice(all_images)\n",
        "\n",
        "# 1. Treinar o modelo se necessário\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"Modelo {MODEL_PATH} não encontrado. Iniciando o treinamento...\")\n",
        "    train_model(DATA_DIR, SELECTED_CLASSES, MODEL_PATH)\n",
        "else:\n",
        "    print(f\"Modelo {MODEL_PATH} encontrado.\")\n",
        "\n",
        "# 2. Extrair features\n",
        "extractor = FeatureExtractor(model_path=MODEL_PATH)\n",
        "if not os.path.exists(FEATURES_PATH):\n",
        "    print(f\"Arquivo de features {FEATURES_PATH} não encontrado. Extraindo features...\")\n",
        "    image_paths_to_process = []\n",
        "    for class_name in SELECTED_CLASSES:\n",
        "        class_dir = os.path.join(DATA_DIR, class_name)\n",
        "        # Ajustado para o dataset que usa .jpg\n",
        "        image_paths_to_process.extend(glob.glob(os.path.join(class_dir, 'image_*.jpg')))\n",
        "\n",
        "    features = extractor.extract_features_from_paths(image_paths_to_process)\n",
        "    extractor.save_features(features, FEATURES_PATH)\n",
        "    print(f\"Features salvas em: {FEATURES_PATH}\")\n",
        "else:\n",
        "    print(f\"Carregando features de: {FEATURES_PATH}\")\n",
        "    features = extractor.load_features(FEATURES_PATH)\n",
        "\n",
        "# 3. Obter recomendações\n",
        "query_image_path = get_random_image(DATA_DIR, SELECTED_CLASSES)\n",
        "query_feature = extractor.extract_feature(query_image_path) # Extrai a feature da imagem de consulta\n",
        "\n",
        "# Adiciona a feature da imagem de consulta ao dicionário se não estiver lá\n",
        "if query_image_path not in features:\n",
        "    features[query_image_path] = query_feature\n",
        "\n",
        "recommender = Recommender(features)\n",
        "recommendations = recommender.get_recommendations(query_image_path, top_k=5)\n",
        "\n",
        "# 4. Exibir resultados\n",
        "print(f\"Buscando recomendações para: {query_image_path}\")\n",
        "print(\"Imagens recomendadas:\")\n",
        "if recommendations:\n",
        "    for img_path, score in recommendations:\n",
        "        print(f\"- {img_path} (Similaridade: {score:.4f})\")\n",
        "else:\n",
        "    print(\"Nenhuma recomendação encontrada.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}